\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Codes Documentation},
            pdfauthor={ANDREW LI},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx}
% grffile has become a legacy package: https://ctan.org/pkg/grffile
\IfFileExists{grffile.sty}{%
\usepackage{grffile}
}{}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Codes Documentation}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{ANDREW LI}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{11/22/2019}


\begin{document}
\maketitle

\hypertarget{description}{%
\subsection{Description}\label{description}}

\textbf{daily\_scraping.py} is a multi-processes and multi-threads
enabled program for scraping the inforation from Eastmoney forum
periodically. This program will be activated twice a day on (1:00 PM and
2:30 PM) and stay silent in background for the rest of the day.

1:00 PM

\begin{quote}
The main purpose of this period is to update the database by adding the
latest data.
\end{quote}

\begin{quote}
The program will scrape the 300 tickers from CSI300. For each ticker,
only one page will be requested at a time. The program will update the
historical data in the database by using latest information.
\end{quote}

\begin{quote}
\textbf{Time complexity}: 15 - 20 minutes (depending on the number of
total post of that day)
\end{quote}

\begin{quote}
\textbf{Concurrency}: 1 Processes and 1 Threads are used, which means
that each process is able to send 1 requests to the remote sever at a
single time point. After acquiring 1 pages information, the program will
take 2 - 3 seconds to parse and reformat the information followed by
downloading the rest of tickers.
\end{quote}

2:30 PM

\begin{quote}
The main purpose of this period is to update the database and create the
daily summary table.
\end{quote}

\begin{quote}
The program will scrape the 300 tickers page by page during this period.
We will compare the timestamp of scraped page with our historical data
to decide whether more pages are needed to be scraped or not.
\end{quote}

\begin{quote}
\textbf{Time complexity}: 10 minutes (depending on the number of post of
that day)
\end{quote}

\begin{quote}
\textbf{Concurrency}: 1 Processes and 1 Thread are used, which means
that each process can only send 1 request to the remote sever at a
single time point.
\end{quote}

\newpage

\hypertarget{work-flow}{%
\subsection{Work Flow}\label{work-flow}}

As shown below, the main process will distribute the tickers to
sub-processes and each sub-process will create threads to request web
page and wait for response independently. After having the complete
information, the data will be formatted by each sub-process.

\includegraphics{Untitled_files/figure-latex/unnamed-chunk-1-1.pdf}

\hypertarget{execution}{%
\subsection{Execution}\label{execution}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  install python3.6 through
  \href{https://www.python.org/downloads/release/python-368/}{here}
\item
  run \texttt{pip\ install\ -r\ requirements.txt} to install required
  dependencies
\item
  run \texttt{python\ -W\ ignore\ daily\_scraping.py}
\end{enumerate}


\end{document}
